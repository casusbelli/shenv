# fish shell config file

alias vim='/opt/homebrew/bin/nvim'
alias rm='/bin/rm -i'
alias ll='ls -lash'
alias gitpowerpull='git pull --all --tags --force; and git submodule sync ; and git submodule update --init --recursive'

fish_add_path /opt/homebrew/bin
fish_add_path ~/Applications

set -U -x GIT_EDITOR nvim
set -U -x EDITOR nvim

function shellai
    # Based off https://notes.suhaib.in/docs/tech/how-to/how-to-build-a-personal-dev-copilot-with-ollama-+-tmux-+-bash/
    set -l model "gpt-oss:20b"  # Default model. Change this to 'mistral', 'codellama', etc.
    set -g prompt ""
    set -l context_from_stdin false

    # Check if we're receiving input via a pipe
    if test (count (commandline -op)) -gt 0
        set -g context_from_stdin true
    end

    # If prompt is provided as arguments, use it
    if test (count $argv) -gt 0
        set -g prompt (string join " " $argv)
    else
        echo "No prompt found."
    end

    echo "Thinking..."  # User feedback

    # Execute ollama. Ollama handles combining prompt args with stdin content.
    if test "$context_from_stdin" = true
        # When stdin is present, ollama reads from it directly.
        # The prompt arguments are passed as the user's specific query.
        ollama run $model $prompt
    else
        # No stdin, just run with the prompt
        if test -z "$prompt"
            echo "Usage: shellai \"Your query here\""
            echo "Or: cat file.py | shellai \"Explain this code\""
            return 1
        end
        ollama run $model $prompt
    end
end
